# House Prices - Advanced Regression Techniques (Kaggle Competition) 
[ðŸ‡©ðŸ‡ª Deutsche Version](#german-version)

This repository contains the solution and analysis for the Kaggle competition **["House Prices: Advanced Regression Techniques"](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)**. The objective of this competition is to predict the final sale price of homes based on a variety of features, such as square footage, number of rooms, location. See the summary report [here](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/reports/summary_report.md).

![](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/reports/images/sale_prices.png)

My main goal was to improve [AutoGluon](https://autogluon.mxnet.io/)â€™s prediction score through data engineering and configuration optimization.

## Key Findings:
- Improved AutoGluon's baseline prediction score by **10.1%** (Table 1).
- Achieved a **top 3% ranking** among nearly 4,200 competitors in the Kaggle competition.

### Table 1: Approaches Employed to Improve Model Performance

| Data                        | AutoGluon Presets, Time (min) | Score (RMSE) | Score Improvement (%) |
|-----------------------------|-------------------------------|--------------|-----------------------|
| Original data               | Default                       | 0.12748      | -                     |
| Original data               | Good, 30                      | 0.12036      | 5.6                   |
| - Feature 'Id'              | Good, 30                      | 0.11632      | 8.8                   |
| + NaN Treatment             | Good, 30                      | 0.11539      | 9.5                   |
| + Median Price (25 Closest) | Good, 30                      | 0.11459      | 10.1                  |

---

## Project Overview

Below is a succinct description of the steps developed in this project.

## [Adding Latitude and Longitude to the Dataset](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/01_ah_merging_datas.ipynb)  
- Combined latitude and longitude information from [R's tidymodels](https://www.tmwr.org/ames) dataset with Kaggle's dataset. While this did not improve the test dataset score (Table 2), it enabled the calculation of the median sale price of the 25 closest houses.
- Produced visualizations (see [here](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/ah_appendix_1.ipynb)).

## [Exploratory Data Analysis and Data Engineering](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/02_ah_EDA.ipynb)  
At this stage, I went through several procedures:  
1. **Sanity check**
- Inspected for duplicate entries, standardized text data, and analyzed missing values.
- Dropped the 'Id' feature, improving the test dataset score by **3.2%** (Table 1).
- Tested dropping categorical features that lacked a second representative category in the training dataset, but this approach did not improve the score on the test dataset (Table 2).

2. **Missing values treatment**
- Implemented a custom approach for handling missing values, resulting in a **0.7%** improvement over AutoGluon's default method (Table 1).
  
3. **Categorical features**
- Tested combining underrepresented categories and grouping neighborhoods, but neither approach improved the score (Table 2).

4. **Numeric features**
- Experimented with delta features, seasonal features, and area-related features, but none improved the score (Table 2).

5. **Numeric vs. non-numeric features**
- Explored an alternative encoding method for ordinal features (see [here](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/ah_appendix_2.ipynb)), but this did not improve the score (Table 2).
  
6. **Outliers**
- Evaluated the impact of removing extreme outliers, but this did not improve the score (Table 2).
  
7. **New feature based on location**
- Introduced a feature representing the median sale price of the 25 closest houses, with the number of neighboring houses determined through experimentation (values tested: 5, 25, 50, 75, and 100). This feature yielded a **0.6%** improvement (Table 1).

8. **New feature based on economic data**
- Tested two economic indexes related to housing prices, but these features did not improve model performance (Table 2).

9. **Interaction between original features**
- Experimented with creating interaction features by combining pairs of the top numeric/ordinal features (e.g., 'GrLivArea' * 'OverallQual') based on AutoGluonâ€™s feature importance ranking. I tested combinations of the top 3, 5, and 10 features, but this approach did not improve the test dataset score (Table 2). A caveat is that AutoGluon's feature importance ranking is intended for use on the test dataset; however, since I do not have the SalePrice for the test dataset, I applied it to the training dataset instead. 

## [Machine Learning](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/03_ah_MODEL.ipynb)  
- I used **AutoGluon** to perform the machine learning analyses.  
- The analyses were conducted using the `presets='good_quality'` and `time_limit=30 min` (the "good_quality" preset typically completes in under 30 minutes). The `medium_quality`, `high_quality`, and `best_quality` presets did not improve the score on the test dataset (see Table 2).  
- Neither the **AutoGluon pseudolabel model refit** nor **model distillation** improved the score on the test dataset (Table 2).  

### Table 2: Proposed Treatments That Did Not Improve Scores

| **Treatments**                                                                 |
|--------------------------------------------------------------------------------|
| Removing 'Street', 'Utilities', 'RoofMatl', 'Condition2', 'PoolQC'             |
| Longitude and Latitude                                                         |
| Combining Underrepresented Classes                                             |
| Grouping Neighborhoods into Larger Areas                                       |
| Defining Seasons of the Year                                                   |
| Delta Features for Construction, Remodeling, and Selling Years                |
| Total Area, Finished Area, High-Quality Area, and Total Bathrooms              |
| Ordinal Encoding                                                               |
| Removing Extreme Outliers                                                      |
| Case-Shiller U.S. National Home Price Index                                    |
| All-Transactions House Price Index for Ames, IA                                |
| Interaction Features Among Top Features                                        |
| AutoGluon Presets: `medium_quality`, `high_quality`, `best_quality`            |
| AutoGluon Pseudolabel Model Refit and Model Distillation                       |

---

## Tools and Technologies:
- **Libraries**: AutoGluon, Featuretools, Matplotlib, Numpy, Pandas, Seaborn, Scikit-Learn, 

---

## Project organization
```
â”œâ”€â”€ .gitignore                              <- Files and directories to be ignored by Git
|
â”œâ”€â”€ LICENSE                                 <- License type 
|
â”œâ”€â”€ README.md                               <- Main README explaining the project
|
â”œâ”€â”€ data                                    <- Project data files
|   â”œâ”€â”€ ames_dataset.csv                    <- Original dataset from R's tidymodels
|   â”œâ”€â”€ ATNHPIUS11180Q.csv                  <- Data for Ames' House Price Index
|   â”œâ”€â”€ clean_data.csv                      <- Dataset prepared for machine learning analysis
|   â”œâ”€â”€ CSUSHPINSA.csv                      <- Data for the USA's Case-Shiller Index
|   â”œâ”€â”€ original_plus_lat_lon.csv           <- Kaggle dataset with added longitude and latitude from tidymodels
|   â”œâ”€â”€ test.csv                            <- Original test dataset from Kaggle
|   â”œâ”€â”€ train.csv                           <- Original train dataset from Kaggle
|
â”œâ”€â”€ environments                            <- Requirements files to reproduce the analysis environments
|   â”œâ”€â”€ autogluon_environment.yml           <- Environment for running '03_ah_MODEL.ipynb' 
|   â”œâ”€â”€ eda_environment.yml                 <- Environment for running '01_ah_merging_datas.ipynb', '02_ah_EDA.ipynb', and 'ah_appendix_2.ipynb' 
|   â”œâ”€â”€ maps_environment.yml                <- Environment for running 'ah_appendix_1.ipynb'
|
â”œâ”€â”€ models                                  <- Trained and serialized models, model predictions, or model summaries
|
â”œâ”€â”€ notebooks                               <- Jupyter notebooks
|   â”œâ”€â”€ 01_ah_merging_datas.ipynb           <- Adding latitude and longitude information to Kaggle's dataset
|   â”œâ”€â”€ 02_ah_EDA.ipynb                     <- Exploratory data analysis
|   â”œâ”€â”€ 03_ah_MODEL.ipynb                   <- Machine learning approach
|   â”œâ”€â”€ ah_appendix_1.ipynb                 <- Creating maps
|   â”œâ”€â”€ ah_appendix_2.ipynb                 <- Exploring an alternative dataset transformation
|   â””â”€â”€ src                                 <- Source code used in this project
|       â”œâ”€â”€ __init__.py                     <- Makes this a Python module
|       â”œâ”€â”€ auxiliaries.py                  <- Scripts to compute nearest houses and median sale prices
|       â”œâ”€â”€ config.py                       <- Basic project configuration
|       â”œâ”€â”€ eda.py                          <- Scripts for exploratory data analysis and visualizations
|
â”œâ”€â”€ references                              <- Data dictionaries, manuals, and other explanatory materials
|   â”œâ”€â”€ data_description.txt                <- Description of the dataset as presented on Kaggle
|
â”œâ”€â”€ reports                                 <- Generated analyses in HTML, PDF, LaTeX, etc., and results
|   â”œâ”€â”€ best_kaggle_prediction.csv          <- Best prediction from Kaggle competition
|   â”œâ”€â”€ summary_report.md                   <- Summary report
â”‚   â””â”€â”€ images                              <- Images used in the project
|      â”œâ”€â”€ sale_prices_train_test_plot.png  <- Map showing houses with and without prices 
|      â”œâ”€â”€ sale_prices.png                  <- Map displaying house prices
```

## Contributing
All contributions are welcome!

### Issues
Submit issues for:
- Recommendations or improvements
- Additional analyses or models
- Feature enhancements
- Bug reports

### Pull Requests
- Open an issue before starting work.
- Fork the repository and clone it.
- Create a branch and commit your changes.
- Push your changes and open a pull request for review.


# German Version

# Hauspreise - Fortgeschrittene Regressionsmethoden (Kaggle-Wettbewerb)

Dieses Repository enthÃ¤lt die LÃ¶sung und Analyse fÃ¼r den Kaggle-Wettbewerb **["House Prices: Advanced Regression Techniques"](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)**. Das Ziel dieses Wettbewerbs ist es, den endgÃ¼ltigen Verkaufspreis von HÃ¤usern basierend auf verschiedenen Merkmalen wie Quadratmeterzahl, Anzahl der Zimmer und Lage vorherzusagen. Siehe den zusammenfassenden Bericht [hier](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/reports/summary_report.md).

![](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/reports/images/sale_prices.png)

Mein Hauptziel war es, die Vorhersagegenauigkeit von [AutoGluon](https://autogluon.mxnet.io/) durch Datenengineering und Konfigurationsoptimierung zu verbessern.

## Wichtige Erkenntnisse:
- Verbesserung der Baseline-Vorhersagegenauigkeit von AutoGluon um **10,1 %** (Tabelle 1).
- Erreichen eines **Top-3%-Rangs** unter fast 4.200 Teilnehmern im Kaggle-Wettbewerb.

### Tabelle 1: Angewandte AnsÃ¤tze zur Verbesserung der Modellleistung

| Daten                        | AutoGluon-Voreinstellungen, Zeit (min) | Score (RMSE) | Verbesserung des Scores (%) |
|-----------------------------|----------------------------------------|--------------|-----------------------------|
| Originaldaten               | Standard                               | 0,12748      | -                           |
| Originaldaten               | Gut, 30                                | 0,12036      | 5,6                         |
| - Merkmal 'Id'              | Gut, 30                                | 0,11632      | 8,8                         |
| + NaN-Behandlung            | Gut, 30                                | 0,11539      | 9,5                         |
| + Medianpreis (25 nÃ¤chste)  | Gut, 30                                | 0,11459      | 10,1                        |

---

## ProjektÃ¼bersicht

Nachfolgend finden Sie eine kurze Beschreibung der in diesem Projekt entwickelten Schritte.

## [HinzufÃ¼gen von Breiten- und LÃ¤ngengraden zum Datensatz](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/01_ah_merging_datas.ipynb)  
- Kombination von Breiten- und LÃ¤ngengradinformationen aus dem [R tidymodels](https://www.tmwr.org/ames)-Datensatz mit dem Kaggle-Datensatz. Obwohl dies die Testdatensatz-Bewertung nicht verbesserte (Tabelle 2), ermÃ¶glichte es die Berechnung des medianen Verkaufspreises der 25 nÃ¤chsten HÃ¤user.
- Erstellung von Visualisierungen (siehe [hier](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/ah_appendix_1.ipynb)).

## [Explorative Datenanalyse und Datenengineering](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/02_ah_EDA.ipynb)  
In dieser Phase durchlief ich mehrere Verfahren:  
1. **PlausibilitÃ¤tsprÃ¼fung**
- ÃœberprÃ¼fung auf doppelte EintrÃ¤ge, Standardisierung von Textdaten und Analyse fehlender Werte.
- Entfernung des Merkmals 'Id', was die Testdatensatz-Bewertung um **3,2 %** verbesserte (Tabelle 1).
- Test der Entfernung kategorischer Merkmale, die im Trainingsdatensatz keine zweite reprÃ¤sentative Kategorie aufwiesen, was jedoch die Testdatensatz-Bewertung nicht verbesserte (Tabelle 2).

2. **Behandlung fehlender Werte**
- Implementierung eines benutzerdefinierten Ansatzes zur Behandlung fehlender Werte, was zu einer **0,7 %**-Verbesserung gegenÃ¼ber der Standardmethode von AutoGluon fÃ¼hrte (Tabelle 1).
  
3. **Kategorische Merkmale**
- Test der Kombination unterreprÃ¤sentierter Kategorien und Gruppierung von Nachbarschaften, was jedoch die Bewertung nicht verbesserte (Tabelle 2).

4. **Numerische Merkmale**
- Experimente mit Delta-Merkmalen, saisonalen Merkmalen und flÃ¤chenbezogenen Merkmalen, die jedoch die Bewertung nicht verbesserten (Tabelle 2).

5. **Numerische vs. nicht-numerische Merkmale**
- Erforschung einer alternativen Kodierungsmethode fÃ¼r ordinale Merkmale (siehe [hier](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/ah_appendix_2.ipynb)), was jedoch die Bewertung nicht verbesserte (Tabelle 2).
  
6. **AusreiÃŸer**
- Bewertung der Auswirkungen der Entfernung extremer AusreiÃŸer, was jedoch die Bewertung nicht verbesserte (Tabelle 2).
  
7. **Neues Merkmal basierend auf der Lage**
- EinfÃ¼hrung eines Merkmals, das den medianen Verkaufspreis der 25 nÃ¤chsten HÃ¤user darstellt, wobei die Anzahl der NachbarhÃ¤user durch Experimente bestimmt wurde (getestete Werte: 5, 25, 50, 75 und 100). Dieses Merkmal fÃ¼hrte zu einer **0,6 %**-Verbesserung (Tabelle 1).

8. **Neues Merkmal basierend auf Wirtschaftsdaten**
- Test zweier Wirtschaftsindizes im Zusammenhang mit Hauspreisen, die jedoch die Modellleistung nicht verbesserten (Tabelle 2).

9. **Interaktion zwischen ursprÃ¼nglichen Merkmalen**
- Experimente mit der Erstellung von Interaktionsmerkmalen durch Kombination von Paaren der wichtigsten numerischen/ordinalen Merkmale (z.B. 'GrLivArea' * 'OverallQual') basierend auf der Merkmalswichtigkeitsrangliste von AutoGluon. Ich testete Kombinationen der Top 3, 5 und 10 Merkmale, aber dieser Ansatz verbesserte die Testdatensatz-Bewertung nicht (Tabelle 2). Ein Vorbehalt ist, dass die Merkmalswichtigkeitsrangliste von AutoGluon fÃ¼r die Verwendung auf dem Testdatensatz gedacht ist; da ich jedoch den SalePrice fÃ¼r den Testdatensatz nicht habe, wendete ich sie stattdessen auf den Trainingsdatensatz an.

## [Maschinelles Lernen](https://github.com/alexhubbe/house_prices_kaggle_competition/blob/master/notebooks/03_ah_MODEL.ipynb)  
- Ich verwendete **AutoGluon**, um die maschinellen Lernanalysen durchzufÃ¼hren.  
- Die Analysen wurden mit den Voreinstellungen `presets='good_quality'` und `time_limit=30 min` durchgefÃ¼hrt (die "good_quality"-Voreinstellung ist in der Regel in weniger als 30 Minuten abgeschlossen). Die Voreinstellungen `medium_quality`, `high_quality` und `best_quality` verbesserten die Bewertung des Testdatensatzes nicht (siehe Tabelle 2).  
- Weder das **AutoGluon Pseudolabel Model Refit** noch die **Modelldestillation** verbesserten die Bewertung des Testdatensatzes (Tabelle 2).  

### Tabelle 2: Vorgeschlagene Behandlungen, die die Bewertungen nicht verbesserten

| **Behandlungen**                                                                 |
|--------------------------------------------------------------------------------|
| Entfernung von 'Street', 'Utilities', 'RoofMatl', 'Condition2', 'PoolQC'       |
| LÃ¤ngen- und Breitengrad                                                       |
| Kombination unterreprÃ¤sentierter Klassen                                       |
| Gruppierung von Nachbarschaften in grÃ¶ÃŸere Gebiete                             |
| Definition der Jahreszeiten                                                   |
| Delta-Merkmale fÃ¼r Bau-, Umbau- und Verkaufsjahre                             |
| GesamtflÃ¤che, fertiggestellte FlÃ¤che, hochwertige FlÃ¤che und Gesamtzahl der Badezimmer |
| Ordinale Kodierung                                                            |
| Entfernung extremer AusreiÃŸer                                                  |
| Case-Shiller U.S. National Home Price Index                                    |
| All-Transactions House Price Index fÃ¼r Ames, IA                                |
| Interaktionsmerkmale unter den Top-Merkmalen                                   |
| AutoGluon-Voreinstellungen: `medium_quality`, `high_quality`, `best_quality`   |
| AutoGluon Pseudolabel Model Refit und Modelldestillation                       |

---

## Tools und Technologien:
- **Bibliotheken**: AutoGluon, Featuretools, Matplotlib, Numpy, Pandas, Seaborn, Scikit-Learn, 

---

## Projektorganisation
```
â”œâ”€â”€ .gitignore                              <- Dateien und Verzeichnisse, die von Git ignoriert werden sollen
|
â”œâ”€â”€ LICENSE                                 <- Lizenztyp 
|
â”œâ”€â”€ README.md                               <- Haupt-README, die das Projekt erklÃ¤rt
|
â”œâ”€â”€ data                                    <- Projektdateien
|   â”œâ”€â”€ ames_dataset.csv                    <- Originaldatensatz von R's tidymodels
|   â”œâ”€â”€ ATNHPIUS11180Q.csv                  <- Daten fÃ¼r den Hauspreisindex von Ames
|   â”œâ”€â”€ clean_data.csv                      <- FÃ¼r die maschinelle Lernanalyse vorbereiteter Datensatz
|   â”œâ”€â”€ CSUSHPINSA.csv                      <- Daten fÃ¼r den Case-Shiller-Index der USA
|   â”œâ”€â”€ original_plus_lat_lon.csv           <- Kaggle-Datensatz mit hinzugefÃ¼gten LÃ¤ngen- und Breitengraden von tidymodels
|   â”œâ”€â”€ test.csv                            <- Originaler Testdatensatz von Kaggle
|   â”œâ”€â”€ train.csv                           <- Originaler Trainingsdatensatz von Kaggle
|
â”œâ”€â”€ environments                            <- Anforderungsdateien zur Reproduktion der Analyseumgebungen
|   â”œâ”€â”€ autogluon_environment.yml           <- Umgebung fÃ¼r die AusfÃ¼hrung von '03_ah_MODEL.ipynb' 
|   â”œâ”€â”€ eda_environment.yml                 <- Umgebung fÃ¼r die AusfÃ¼hrung von '01_ah_merging_datas.ipynb', '02_ah_EDA.ipynb' und 'ah_appendix_2.ipynb' 
|   â”œâ”€â”€ maps_environment.yml                <- Umgebung fÃ¼r die AusfÃ¼hrung von 'ah_appendix_1.ipynb'
|
â”œâ”€â”€ models                                  <- Trainierte und serialisierte Modelle, Modellvorhersagen oder Modellzusammenfassungen
|
â”œâ”€â”€ notebooks                               <- Jupyter-Notebooks
|   â”œâ”€â”€ 01_ah_merging_datas.ipynb           <- HinzufÃ¼gen von LÃ¤ngen- und Breitengradinformationen zum Kaggle-Datensatz
|   â”œâ”€â”€ 02_ah_EDA.ipynb                     <- Explorative Datenanalyse
|   â”œâ”€â”€ 03_ah_MODEL.ipynb                   <- Ansatz des maschinellen Lernens
|   â”œâ”€â”€ ah_appendix_1.ipynb                 <- Erstellung von Karten
|   â”œâ”€â”€ ah_appendix_2.ipynb                 <- Erforschung einer alternativen Datensatztransformation
|   â””â”€â”€ src                                 <- In diesem Projekt verwendeter Quellcode
|       â”œâ”€â”€ __init__.py                     <- Macht dies zu einem Python-Modul
|       â”œâ”€â”€ auxiliaries.py                  <- Skripte zur Berechnung der nÃ¤chsten HÃ¤user und medianen Verkaufspreise
|       â”œâ”€â”€ config.py                       <- Grundlegende Projektkonfiguration
|       â”œâ”€â”€ eda.py                          <- Skripte fÃ¼r explorative Datenanalyse und Visualisierungen
|
â”œâ”€â”€ references                              <- DatenwÃ¶rterbÃ¼cher, HandbÃ¼cher und andere erklÃ¤rende Materialien
|   â”œâ”€â”€ data_description.txt                <- Beschreibung des Datensatzes, wie auf Kaggle prÃ¤sentiert
|
â”œâ”€â”€ reports                                 <- Generierte Analysen in HTML, PDF, LaTeX usw. und Ergebnisse
|   â”œâ”€â”€ best_kaggle_prediction.csv          <- Beste Vorhersage aus dem Kaggle-Wettbewerb
|   â”œâ”€â”€ summary_report.md                   <- Zusammenfassenden Bericht
â”‚   â””â”€â”€ images                              <- Im Projekt verwendete Bilder
|      â”œâ”€â”€ sale_prices_train_test_plot.png  <- Karte mit HÃ¤usern mit und ohne Preise 
|      â”œâ”€â”€ sale_prices.png                  <- Karte mit Hauspreisen
```

## Mitwirkung
Alle BeitrÃ¤ge sind willkommen!

### Probleme
Reichen Sie Probleme ein fÃ¼r:
- Empfehlungen oder Verbesserungen
- ZusÃ¤tzliche Analysen oder Modelle
- Funktionserweiterungen
- Fehlermeldungen

### Pull Requests
- Ã–ffnen Sie ein Problem, bevor Sie mit der Arbeit beginnen.
- Forken Sie das Repository und klonen Sie es.
- Erstellen Sie einen Branch und committen Sie Ihre Ã„nderungen.
- Pushen Sie Ihre Ã„nderungen und Ã¶ffnen Sie einen Pull Request zur ÃœberprÃ¼fung.
