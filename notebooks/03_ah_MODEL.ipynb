{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cae1ecb-ba50-4e9d-808a-8276bacdb12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "from src.config import (\n",
    "    PLUS_LON_LAT_DATA,\n",
    "    TRAIN_DATA,\n",
    "    TEST_DATA,\n",
    "    CLEAN_DATA\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b28c57-4538-4bbd-8c11-ab6e1f54e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 227)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_transformed.csv')\n",
    "print(df.shape)\n",
    "df_train = df.loc[~df['SalePrice'].isnull()]\n",
    "df_test = df.loc[df['SalePrice'].isnull()]\n",
    "\n",
    "id = df_test['Id']\n",
    "\n",
    "df_train = df_train.drop('Id', axis=1)\n",
    "df_test = df_test.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a471961-18d1-4900-afcc-6adf187f84a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass_30', 'MSSubClass_40', 'MSSubClass_45', 'MSSubClass_50',\n",
       "       'MSSubClass_60', 'MSSubClass_70', 'MSSubClass_75', 'MSSubClass_80',\n",
       "       'MSSubClass_85', 'MSSubClass_90',\n",
       "       ...\n",
       "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
       "       'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'Id', 'SalePrice'],\n",
       "      dtype='object', length=227)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeee85b8-3f83-42fc-a160-35acf0a55272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250115_113829\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Wed Dec 11 22:24:04 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.21 GB / 7.56 GB (29.3%)\n",
      "Disk Space Avail:   1586.62 GB / 1832.70 GB (86.6%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 450s of the 1800.0s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-01-15 12:38:38,769\tINFO worker.py:1762 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"AutogluonModels/ag-20250115_113829/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Beginning AutoGluon training ... Time limit = 440s\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20250115_113829/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Train Data Rows:    1297\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Train Data Columns: 225\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Label Column:       SalePrice\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tAvailable Memory:                    1617.72 MB\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tTrain Data (Original)  Memory Usage: 2.23 MB (0.1% of available memory)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\t\tNote: Converting 166 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tUseless Original Features (Count: 6): ['MSSubClass_150', 'MSZoning_i', 'Exterior1st_precast', 'Exterior2nd_precast', 'SaleType_vwd', 'MasVnrType_cblock']\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tUnused Original Features (Count: 2): ['BldgType_duplex', 'Exterior2nd_cblock']\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\t('float', []) : 2 | ['BldgType_duplex', 'Exterior2nd_cblock']\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\t('float', []) : 217 | ['MSSubClass_30', 'MSSubClass_40', 'MSSubClass_45', 'MSSubClass_50', 'MSSubClass_60', ...]\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\t('float', [])     :  53 | ['FireplaceQu', 'LotShape', 'LandSlope', 'OverallQual', 'OverallCond', ...]\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\t('int', ['bool']) : 164 | ['MSSubClass_30', 'MSSubClass_40', 'MSSubClass_45', 'MSSubClass_50', 'MSSubClass_60', ...]\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t1.4s = Fit runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t217 features in original data used to generate 217 features in processed data.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.73 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Data preprocessing and feature engineering runtime = 1.42s ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t'NN_TORCH': {},\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t'CAT': {},\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t'XGB': {},\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t'FASTAI': {},\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 9 L1 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 292.15s of the 438.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=2.74%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=18072)\u001b[0m [1000]\tvalid_set's rmse: 0.153711\n",
      "\u001b[36m(_ray_fit pid=18072)\u001b[0m [2000]\tvalid_set's rmse: 0.153116\n",
      "\u001b[36m(_ray_fit pid=18072)\u001b[0m [3000]\tvalid_set's rmse: 0.153014\n",
      "\u001b[36m(_ray_fit pid=18072)\u001b[0m [4000]\tvalid_set's rmse: 0.152998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1219\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t14.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 274.47s of the 420.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=2.33%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=18311)\u001b[0m [1000]\tvalid_set's rmse: 0.14959\n",
      "\u001b[36m(_ray_fit pid=18135)\u001b[0m [1000]\tvalid_set's rmse: 0.136867\n",
      "\u001b[36m(_ray_fit pid=18135)\u001b[0m [5000]\tvalid_set's rmse: 0.135304\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18135)\u001b[0m [9000]\tvalid_set's rmse: 0.1353\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1268\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t17.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.65s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 254.21s of the 400.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1394\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t2.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 251.17s of the 397.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=4.02%)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1145\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t25.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.52s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 223.89s of the 370.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1373\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t1.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 222.37s of the 368.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=0.33%)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18986, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 211.01s of the 357.2s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=7.00%)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.13\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t5.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 201.99s of the 348.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_ray_fit pid=19651)\u001b[0m /home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=19651)\u001b[0m The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "\u001b[36m(_ray_fit pid=19651)\u001b[0m At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "\u001b[36m(_ray_fit pid=19651)\u001b[0m To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\u001b[36m(_ray_fit pid=19651)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=19651)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_ray_fit pid=19646)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=19650)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=19645)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=19647)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=19648)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=19707)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=19649)\u001b[0m \n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=18991, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=18990, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=18989, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=18988, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=18985, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=19651, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 205, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     raise TimeLimitExceeded\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=19646, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 205, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     raise TimeLimitExceeded\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 184.64s of the 330.82s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=19649)\u001b[0m /home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19649)\u001b[0m The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19649)\u001b[0m At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19649)\u001b[0m To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19649)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.18% memory usage per fold, 56.73%/80.00% total).\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=14.18%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=20040)\u001b[0m [1000]\tvalid_set's rmse: 0.120721\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=20040)\u001b[0m [2000]\tvalid_set's rmse: 0.120707\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1346\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t23.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.91s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 297.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.8, 'LightGBMXT_BAG_L1': 0.133, 'LightGBM_BAG_L1': 0.067}\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1141\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 9 L2 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 297.05s of the 297.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=1.73%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=20470)\u001b[0m [1000]\tvalid_set's rmse: 0.160354\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1256\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t7.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.21s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 286.48s of the 286.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=1.98%)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1214\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t4.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 279.82s of the 279.81s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1204\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t2.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 277.25s of the 277.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=3.25%)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1173\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t17.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 257.54s of the 257.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1185\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t1.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 256.12s of the 256.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=0.32%)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21577, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 250.61s of the 250.6s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=4.43%)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1226\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t4.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 243.61s of the 243.6s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_ray_fit pid=22168)\u001b[0m /home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=22168)\u001b[0m The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "\u001b[36m(_ray_fit pid=22168)\u001b[0m At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "\u001b[36m(_ray_fit pid=22168)\u001b[0m To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\u001b[36m(_ray_fit pid=22168)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=22168)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_ray_fit pid=22163)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=22169)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=22165)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=22164)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=22166)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=22302)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=22167)\u001b[0m \n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1184\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t13.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.28s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 228.04s of the 228.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=5.88%)\n",
      "\u001b[36m(_ray_fit pid=22167)\u001b[0m /home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=22167)\u001b[0m The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=22167)\u001b[0m At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=22167)\u001b[0m To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=22167)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1244\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t10.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 214.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'NeuralNetTorch_BAG_L2': 0.312, 'CatBoost_BAG_L2': 0.125, 'LightGBMLarge_BAG_L2': 0.062}\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t-0.1127\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m AutoGluon training complete, total runtime = 226.11s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 59.7 rows/s (163 batch size)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21573, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21579, ip=192.168.0.73)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import autogluon.tabular.models.fastainn.imports_helper\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from fastai.tabular.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .data.all import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from ..torch_basics import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from .imports import *\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _api, _version, cbook, _docstring, rcsetup\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from matplotlib.colors import Colormap, is_color_like\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from PIL import Image\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m     from . import _imaging as core\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t1.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t2.54s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t2.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t2.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t1.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t3.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.8, 'LightGBMXT_BAG_L1': 0.133, 'LightGBM_BAG_L1': 0.067}\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t2.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t1.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m /home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t1.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t1.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'NeuralNetTorch_BAG_L2': 0.312, 'CatBoost_BAG_L2': 0.125, 'LightGBMLarge_BAG_L2': 0.062}\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Refit complete, total runtime = 22.27s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20250115_113829/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=17718)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L3_FULL      -0.137372  -0.112744  root_mean_squared_error        0.335889            NaN  18.732102                 0.002450                     NaN           0.031073            3       True         17\n",
      "1          LightGBM_BAG_L2_FULL      -0.139512  -0.121447  root_mean_squared_error        0.295766            NaN  15.335352                 0.004527                     NaN           0.236018            2       True         10\n",
      "2      WeightedEnsemble_L2_FULL      -0.139691  -0.114063  root_mean_squared_error        0.070824            NaN   6.282177                 0.003268                     NaN           0.121947            2       True          8\n",
      "3          CatBoost_BAG_L1_FULL      -0.140084  -0.114472  root_mean_squared_error        0.009638            NaN   2.579682                 0.009638                     NaN           2.579682            1       True          4\n",
      "4    NeuralNetTorch_BAG_L2_FULL      -0.140523  -0.118380  root_mean_squared_error        0.308406            NaN  17.025576                 0.017166                     NaN           1.926242            2       True         15\n",
      "5   RandomForestMSE_BAG_L2_FULL      -0.140720  -0.120378  root_mean_squared_error        0.361865            NaN  17.535799                 0.070626                0.095028           2.436465            2       True         11\n",
      "6     ExtraTreesMSE_BAG_L2_FULL      -0.140769  -0.118484  root_mean_squared_error        0.361457            NaN  16.372976                 0.070218                0.102691           1.273642            2       True         13\n",
      "7          CatBoost_BAG_L2_FULL      -0.141523  -0.117281  root_mean_squared_error        0.305839            NaN  15.696581                 0.014600                     NaN           0.597247            2       True         12\n",
      "8     LightGBMLarge_BAG_L2_FULL      -0.144702  -0.124431  root_mean_squared_error        0.301673            NaN  16.177540                 0.010434                     NaN           1.078206            2       True         16\n",
      "9        LightGBMXT_BAG_L2_FULL      -0.145410  -0.125578  root_mean_squared_error        0.310445            NaN  15.958534                 0.019205                     NaN           0.859200            2       True          9\n",
      "10          XGBoost_BAG_L2_FULL      -0.146830  -0.122569  root_mean_squared_error        0.296096            NaN  15.354805                 0.004857                     NaN           0.255471            2       True         14\n",
      "11         LightGBM_BAG_L1_FULL      -0.147380  -0.126771  root_mean_squared_error        0.046201            NaN   2.542184                 0.046201                     NaN           2.542184            1       True          2\n",
      "12       LightGBMXT_BAG_L1_FULL      -0.148200  -0.121861  root_mean_squared_error        0.011717            NaN   1.038363                 0.011717                     NaN           1.038363            1       True          1\n",
      "13    LightGBMLarge_BAG_L1_FULL      -0.154496  -0.134555  root_mean_squared_error        0.059117            NaN   3.950814                 0.059117                     NaN           3.950814            1       True          7\n",
      "14  RandomForestMSE_BAG_L1_FULL      -0.155114  -0.139355  root_mean_squared_error        0.089410       0.094864   2.891922                 0.089410                0.094864           2.891922            1       True          3\n",
      "15          XGBoost_BAG_L1_FULL      -0.155806  -0.129977  root_mean_squared_error        0.010288            NaN   0.720781                 0.010288                     NaN           0.720781            1       True          6\n",
      "16    ExtraTreesMSE_BAG_L1_FULL      -0.160626  -0.137276  root_mean_squared_error        0.064869       0.101383   1.375587                 0.064869                0.101383           1.375587            1       True          5\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t263s\t = DyStack   runtime |\t1537s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 1537s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20250115_113829\"\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 225\n",
      "Label Column:       SalePrice\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2971.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.51 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 166 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 6): ['MSSubClass_150', 'MSZoning_i', 'Exterior1st_precast', 'Exterior2nd_precast', 'SaleType_vwd', 'MasVnrType_cblock']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['BldgType_duplex', 'Exterior2nd_cblock']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 2 | ['BldgType_duplex', 'Exterior2nd_cblock']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 217 | ['MSSubClass_30', 'MSSubClass_40', 'MSSubClass_45', 'MSSubClass_50', 'MSSubClass_60', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  53 | ['FireplaceQu', 'LotShape', 'LandSlope', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) : 164 | ['MSSubClass_30', 'MSSubClass_40', 'MSSubClass_45', 'MSSubClass_50', 'MSSubClass_60', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t217 features in original data used to generate 217 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1022.86s of the 1534.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=1.33%)\n",
      "\t-0.1263\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.84s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1016.6s of the 1528.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=1.40%)\n",
      "\t-0.1282\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.32s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 996.92s of the 1508.73s of remaining time.\n",
      "\t-0.1405\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.86s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 992.9s of the 1504.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=2.56%)\n",
      "\t-0.1195\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.22s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 959.63s of the 1471.44s of remaining time.\n",
      "\t-0.1385\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 958.1s of the 1469.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=0.28%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=24124, ip=192.168.0.73)\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "    try_import_fastai()\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "    import autogluon.tabular.models.fastainn.imports_helper\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "    from fastai.tabular.all import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "    from ..basics import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "    from .data.all import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "    from ..torch_basics import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "    from .imports import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "    import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "    from PIL import Image\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "    from . import _imaging as core\n",
      "ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 952.53s of the 1464.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=2.71%)\n",
      "2025-01-15 12:44:10,108\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:44:11,186\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:44:11,199\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:44:11,201\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:44:11,203\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:44:11,204\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:44:11,206\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.1336\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.88s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 944.72s of the 1456.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t-0.1245\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.32s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 929.19s of the 1441.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=6.26%)\n",
      "\t-0.1351\t = Validation score   (-root_mean_squared_error)\n",
      "\t58.13s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1379.74s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.45, 'NeuralNetTorch_BAG_L1': 0.35, 'LightGBM_BAG_L1': 0.2}\n",
      "\t-0.1163\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1379.56s of the 1379.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=1.64%)\n",
      "\t-0.1264\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.19s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1366.06s of the 1366.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=1.56%)\n",
      "\t-0.1233\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.09s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 1342.65s of the 1342.64s of remaining time.\n",
      "\t-0.1194\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.73s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1339.76s of the 1339.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=2.87%)\n",
      "\t-0.1194\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.7s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 1327.97s of the 1327.97s of remaining time.\n",
      "\t-0.1197\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1326.3s of the 1326.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=26833, ip=192.168.0.73)\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "    try_import_fastai()\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 119, in try_import_fastai\n",
      "    import autogluon.tabular.models.fastainn.imports_helper\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "    from fastai.tabular.all import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "    from ..basics import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "    from .data.all import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "    from ..torch_basics import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "    from .imports import *\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/fastai/imports.py\", line 5, in <module>\n",
      "    import multiprocessing,threading,urllib,tempfile,concurrent.futures,matplotlib,warnings,zipfile\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/matplotlib/colors.py\", line 52, in <module>\n",
      "    from PIL import Image\n",
      "  File \"/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/PIL/Image.py\", line 100, in <module>\n",
      "    from . import _imaging as core\n",
      "ImportError: libtiff.so.5: cannot open shared object file: No such file or directory\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1322.19s of the 1322.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=3.16%)\n",
      "2025-01-15 12:46:33,295\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:46:33,297\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:46:33,298\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:46:33,300\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:46:33,301\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:46:33,302\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-15 12:46:33,304\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.1235\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.08s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1315.14s of the 1315.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t-0.1226\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.98s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1300.98s of the 1300.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=5.61%)\n",
      "\t-0.1263\t = Validation score   (-root_mean_squared_error)\n",
      "\t27.94s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 1269.57s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.25, 'RandomForestMSE_BAG_L2': 0.25, 'NeuralNetTorch_BAG_L1': 0.208, 'LightGBM_BAG_L1': 0.125, 'CatBoost_BAG_L2': 0.125, 'NeuralNetTorch_BAG_L2': 0.042}\n",
      "\t-0.1157\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 267.34s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 48.7 rows/s (183 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.81s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.06s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t3.86s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t2.71s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "\t12.66s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t6.66s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.45, 'NeuralNetTorch_BAG_L1': 0.35, 'LightGBM_BAG_L1': 0.2}\n",
      "\t0.01s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.84s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t1.56s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t2.73s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.63s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "/home/alexhubbe/anaconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "\t12.03s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t2.76s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.25, 'RandomForestMSE_BAG_L2': 0.25, 'NeuralNetTorch_BAG_L1': 0.208, 'LightGBM_BAG_L1': 0.125, 'CatBoost_BAG_L2': 0.125, 'NeuralNetTorch_BAG_L2': 0.042}\n",
      "\t0.03s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 45.09s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20250115_113829\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the fit method: 575.90 seconds\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: log-transform the target variable\n",
    "df_train['SalePrice'] = np.log1p(df_train['SalePrice'])  # Log transform target\n",
    "\n",
    "# Identify the target variable\n",
    "label = 'SalePrice'\n",
    "\n",
    "eval_metric = 'rmse'\n",
    "\n",
    "presets = 'good_quality'\n",
    "#'medium_quality'\n",
    "#'good_quality'\n",
    "#'best_quality'\n",
    "\n",
    "time_limit = 60 * 60 * 0.5\n",
    "\n",
    "\n",
    "# Initialize the TabularPredictor \n",
    "start_time = time.time()\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label, \n",
    "    eval_metric=eval_metric, \n",
    "    #problem_type='regression'\n",
    ").fit(\n",
    "    train_data=df_train, \n",
    "    time_limit=time_limit, \n",
    "    presets=presets,\n",
    "    num_cpus=1 \n",
    ")\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the time taken\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to run the fit method: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d57411-d652-4e09-9cce-b1835b9289e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.127272</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.076836</td>\n",
       "      <td>17.836869</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.133216</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>3.985477</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>3.985477</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-0.134965</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.043051</td>\n",
       "      <td>13.828775</td>\n",
       "      <td>0.043051</td>\n",
       "      <td>13.828775</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.140833</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.013876</td>\n",
       "      <td>26.283865</td>\n",
       "      <td>0.013876</td>\n",
       "      <td>26.283865</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.142804</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.802744</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.802744</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val              eval_metric  pred_time_val  \\\n",
       "0  WeightedEnsemble_L2  -0.127272  root_mean_squared_error       0.076836   \n",
       "1           LightGBMXT  -0.133216  root_mean_squared_error       0.029184   \n",
       "2       NeuralNetTorch  -0.134965  root_mean_squared_error       0.043051   \n",
       "3             CatBoost  -0.140833  root_mean_squared_error       0.013876   \n",
       "4             LightGBM  -0.142804  root_mean_squared_error       0.019547   \n",
       "\n",
       "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  17.836869                0.000368           0.011302            2   \n",
       "1   3.985477                0.029184           3.985477            1   \n",
       "2  13.828775                0.043051          13.828775            1   \n",
       "3  26.283865                0.013876          26.283865            1   \n",
       "4   0.802744                0.019547           0.802744            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True         11  \n",
       "1       True          3  \n",
       "2       True          9  \n",
       "3       True          6  \n",
       "4       True          4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b51b12-f94c-4ce2-ac8a-84d2764d564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00a9be2d-95d0-4764-90db-a51935693e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2217</td>\n",
       "      <td>63202.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2905</td>\n",
       "      <td>92037.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2581</td>\n",
       "      <td>118662.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1503</td>\n",
       "      <td>302685.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2718</td>\n",
       "      <td>216917.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>2095</td>\n",
       "      <td>144905.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>1811</td>\n",
       "      <td>97203.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>2091</td>\n",
       "      <td>113923.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>2101</td>\n",
       "      <td>118849.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>1540</td>\n",
       "      <td>94121.781250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     2217   63202.945312\n",
       "1     2905   92037.671875\n",
       "3     2581  118662.804688\n",
       "5     1503  302685.781250\n",
       "6     2718  216917.968750\n",
       "...    ...            ...\n",
       "2907  2095  144905.968750\n",
       "2910  1811   97203.609375\n",
       "2911  2091  113923.750000\n",
       "2914  2101  118849.453125\n",
       "2918  1540   94121.781250\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = predictor.predict(df_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "predictions = np.expm1(predictions)\n",
    "\n",
    "# Ensure predictions are non-negative (important after inverse transform)\n",
    "predictions = np.maximum(0, predictions)\n",
    "\n",
    "predictions\n",
    "# Create a submission file (Kaggle format)\n",
    "submission = pd.DataFrame({'Id': id, 'SalePrice': predictions})\n",
    "submission.to_csv('pred_data_transformed.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fdc7084-9e6e-4afb-b758-43317fc85f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importance = predictor.feature_importance(df_train, time_limit = time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bebb4fb9-6d45-4b84-b865-5e05b1283732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None):\n",
    "#     print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064734d9-eab3-49cc-a21b-a2179cbe062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance.to_csv('feat_imp_3_nan_treated_plus_neighborhoodgroup_season_outliers_removed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe05609-c6ca-48a5-81b6-e6cff94b9633",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e90dc-81b0-4552-9574-aeffefeee8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_name = str(DATA_FOLDER/\"logistic_regression_round1\")\n",
    "# storage_name = f\"sqlite:///{study_name}.db\"\n",
    "# study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efaa55-2da0-447d-bc03-3757bfa461a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X.iloc[train_indices]\n",
    "# y_train = y[train_indices]\n",
    "\n",
    "# preprocessor = preprocessor_ohe_quantile\n",
    "\n",
    "# best_trial = study.best_trial\n",
    "# best_params = best_trial.params\n",
    "# model = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=1000, **best_params)\n",
    "\n",
    "# # Create pipeline\n",
    "# pipeline_model = Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "# pipeline_model.fit(X_train,y_train)\n",
    "\n",
    "# joblib.dump(pipeline_model, DEPLOYED_MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:autogluon]",
   "language": "python",
   "name": "conda-env-autogluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
