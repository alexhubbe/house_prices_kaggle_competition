{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cae1ecb-ba50-4e9d-808a-8276bacdb12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "from src.config import (\n",
    "    CLEAN_DATA,\n",
    "    MODELS_FOLDER,\n",
    "    KAGGLE_SUBMISSION\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b28c57-4538-4bbd-8c11-ab6e1f54e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 79)\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(CLEAN_DATA)\n",
    "df = pd.read_csv(CLEAN_DATA)\n",
    "print(df.shape)\n",
    "df_train = df.loc[~df['SalePrice'].isnull()]\n",
    "df_test = df.loc[df['SalePrice'].isnull()]\n",
    "\n",
    "id = df_test['Id']\n",
    "\n",
    "df_train = df_train.drop('Id', axis=1)\n",
    "df_test = df_test.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeee85b8-3f83-42fc-a160-35acf0a55272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/home/alexhubbe/MEGA/data_science/portfolio/house_prices/models\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Wed Dec 11 22:24:04 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       4.45 GB / 7.56 GB (58.9%)\n",
      "Disk Space Avail:   1570.53 GB / 1832.70 GB (85.7%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-01-18 08:44:55,545\tINFO worker.py:1762 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/home/alexhubbe/MEGA/data_science/portfolio/house_prices/models/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Beginning AutoGluon training ... Time limit = 1790s\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m AutoGluon will save models to \"/home/alexhubbe/MEGA/data_science/portfolio/house_prices/models/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Train Data Rows:    1297\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Train Data Columns: 77\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Label Column:       SalePrice\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tAvailable Memory:                    3506.43 MB\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tTrain Data (Original)  Memory Usage: 3.26 MB (0.1% of available memory)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t('float', [])  :  4 | ['GarageYrBlt', 'Longitude', 'Latitude', 'Median_n_Closest_SalePrice']\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t('int', [])    : 35 | ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t('object', []) : 38 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t('category', [])  : 37 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t('float', [])     :  4 | ['GarageYrBlt', 'Longitude', 'Latitude', 'Median_n_Closest_SalePrice']\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t('int', [])       : 35 | ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t\t('int', ['bool']) :  1 | ['CentralAir']\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.6s = Fit runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t77 features in original data used to generate 77 features in processed data.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.45 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Data preprocessing and feature engineering runtime = 0.64s ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t'NN_TORCH': [{}],\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t'CAT': [{}],\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t'XGB': [{}],\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t'FASTAI': [{}],\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1192.69s of the 1789.48s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.53%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2831)\u001b[0m [1000]\tvalid_set's rmse: 0.11712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1185\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t45.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 1141.12s of the 1737.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.08%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3289)\u001b[0m [1000]\tvalid_set's rmse: 0.145146\n",
      "\u001b[36m(_ray_fit pid=3282)\u001b[0m [1000]\tvalid_set's rmse: 0.130516\n",
      "\u001b[36m(_ray_fit pid=3289)\u001b[0m [5000]\tvalid_set's rmse: 0.144417\u001b[32m [repeated 10x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3289)\u001b[0m [10000]\tvalid_set's rmse: 0.144415\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1232\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t15.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t1.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1088.51s of the 1685.30s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1401\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t2.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 1085.53s of the 1682.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.00%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1162\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t177.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.21s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 906.37s of the 1503.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1358\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 905.43s of the 1502.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_ray_fit pid=4489)\u001b[0m No improvement since epoch 8: early stopping\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1245\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t21.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 880.22s of the 1477.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.52%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1337\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t9.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 835.06s of the 1431.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1233\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t36.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.29s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 795.86s of the 1392.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.74%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5617)\u001b[0m [1000]\tvalid_set's rmse: 0.145618\n",
      "\u001b[36m(_ray_fit pid=5616)\u001b[0m [1000]\tvalid_set's rmse: 0.125806\n",
      "\u001b[36m(_ray_fit pid=5618)\u001b[0m [2000]\tvalid_set's rmse: 0.159983\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5616)\u001b[0m [4000]\tvalid_set's rmse: 0.125802\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5616)\u001b[0m [6000]\tvalid_set's rmse: 0.125802\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5616)\u001b[0m [8000]\tvalid_set's rmse: 0.125802\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5616)\u001b[0m [10000]\tvalid_set's rmse: 0.125802\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1374\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t45.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t1.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1343.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.2, 'NeuralNetTorch_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.15}\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1111\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 9 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1343.66s of the 1343.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.56%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1183\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t2.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 1338.98s of the 1338.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.64%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1171\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t3.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 1332.71s of the 1332.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1166\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t2.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1330.08s of the 1330.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.04%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1145\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t53.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 1274.25s of the 1274.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1142\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t1.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1273.00s of the 1272.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_ray_fit pid=7047)\u001b[0m No improvement since epoch 9: early stopping\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.12\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t28.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 1241.62s of the 1241.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.17%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1184\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t6.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1212.17s of the 1212.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1217\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t28.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1180.85s of the 1180.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.14%)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.1196\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t10.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 1157.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.25, 'CatBoost_BAG_L2': 0.167, 'NeuralNetFastAI_BAG_L2': 0.167, 'NeuralNetTorch_BAG_L1': 0.125, 'LightGBM_BAG_L2': 0.125, 'NeuralNetFastAI_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L2': 0.083}\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t-0.111\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m AutoGluon training complete, total runtime = 632.95s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 59.1 rows/s (163 batch size)\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t1.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t2.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t27.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tStopping at the best epoch learned earlier - 19.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t21.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t16.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t5.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.2, 'NeuralNetTorch_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.15}\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t2.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t4.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t1.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tStopping at the best epoch learned earlier - 14.\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t16.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t8.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.25, 'CatBoost_BAG_L2': 0.167, 'NeuralNetFastAI_BAG_L2': 0.167, 'NeuralNetTorch_BAG_L1': 0.125, 'LightGBM_BAG_L2': 0.125, 'NeuralNetFastAI_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L2': 0.083}\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Refit complete, total runtime = 115.37s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/alexhubbe/MEGA/data_science/portfolio/house_prices/models/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=2347)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    NeuralNetTorch_BAG_L2_FULL      -0.136503  -0.121723  root_mean_squared_error        0.426124            NaN  81.231471                 0.043359                     NaN           8.746773            2       True         18\n",
      "1      WeightedEnsemble_L3_FULL      -0.139848  -0.110983  root_mean_squared_error        0.509481            NaN  95.066881                 0.003200                     NaN           0.012817            3       True         20\n",
      "2      WeightedEnsemble_L2_FULL      -0.141036  -0.111057  root_mean_squared_error        0.221490            NaN  68.353365                 0.002147                     NaN           0.015764            2       True         10\n",
      "3        LightGBMXT_BAG_L2_FULL      -0.141526  -0.118334  root_mean_squared_error        0.392980            NaN  72.688890                 0.010215                     NaN           0.204193            2       True         11\n",
      "4          CatBoost_BAG_L2_FULL      -0.141786  -0.114531  root_mean_squared_error        0.396268            NaN  77.229384                 0.013503                     NaN           4.744687            2       True         14\n",
      "5     ExtraTreesMSE_BAG_L2_FULL      -0.141894  -0.114200  root_mean_squared_error        0.445850            NaN  73.574958                 0.063085                0.119612           1.090261            2       True         15\n",
      "6   RandomForestMSE_BAG_L2_FULL      -0.142190  -0.116594  root_mean_squared_error        0.451934            NaN  74.899165                 0.069168                0.158999           2.414468            2       True         13\n",
      "7    NeuralNetTorch_BAG_L1_FULL      -0.144081  -0.123302  root_mean_squared_error        0.040242            NaN  16.809778                 0.040242                     NaN          16.809778            1       True          8\n",
      "8        LightGBMXT_BAG_L1_FULL      -0.144459  -0.118485  root_mean_squared_error        0.012779            NaN   0.644748                 0.012779                     NaN           0.644748            1       True          1\n",
      "9          LightGBM_BAG_L2_FULL      -0.144723  -0.117117  root_mean_squared_error        0.392458            NaN  72.715424                 0.009693                     NaN           0.230727            2       True         12\n",
      "10          XGBoost_BAG_L2_FULL      -0.146043  -0.118414  root_mean_squared_error        0.411429            NaN  72.680405                 0.028664                     NaN           0.195708            2       True         17\n",
      "11    LightGBMLarge_BAG_L2_FULL      -0.146905  -0.119607  root_mean_squared_error        0.413518            NaN  73.175322                 0.030753                     NaN           0.690625            2       True         19\n",
      "12         CatBoost_BAG_L1_FULL      -0.147076  -0.116154  root_mean_squared_error        0.088179            NaN  27.298273                 0.088179                     NaN          27.298273            1       True          4\n",
      "13         LightGBM_BAG_L1_FULL      -0.152125  -0.123221  root_mean_squared_error        0.043280            NaN   1.976364                 0.043280                     NaN           1.976364            1       True          2\n",
      "14  NeuralNetFastAI_BAG_L1_FULL      -0.154189  -0.124478  root_mean_squared_error        0.034863            NaN  21.608439                 0.034863                     NaN          21.608439            1       True          6\n",
      "15    LightGBMLarge_BAG_L1_FULL      -0.154254  -0.137437  root_mean_squared_error        0.199352            NaN   5.529250                 0.199352                     NaN           5.529250            1       True          9\n",
      "16          XGBoost_BAG_L1_FULL      -0.156314  -0.133749  root_mean_squared_error        0.028776            NaN   0.547946                 0.028776                     NaN           0.547946            1       True          7\n",
      "17  NeuralNetFastAI_BAG_L2_FULL      -0.157158  -0.119976  root_mean_squared_error        0.420001            NaN  88.988389                 0.037235                     NaN          16.503692            2       True         16\n",
      "18  RandomForestMSE_BAG_L1_FULL      -0.157609  -0.140079  root_mean_squared_error        0.067227       0.090882   2.854971                 0.067227                0.090882           2.854971            1       True          3\n",
      "19    ExtraTreesMSE_BAG_L1_FULL      -0.162966  -0.135786  root_mean_squared_error        0.067419       0.146548   0.744179                 0.067419                0.146548           0.744179            1       True          5\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t764s\t = DyStack   runtime |\t6436s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 6436s\n",
      "AutoGluon will save models to \"/home/alexhubbe/MEGA/data_science/portfolio/house_prices/models\"\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 77\n",
      "Label Column:       SalePrice\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3455.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.67 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  4 | ['GarageYrBlt', 'Longitude', 'Latitude', 'Median_n_Closest_SalePrice']\n",
      "\t\t('int', [])    : 35 | ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 38 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 37 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  4 | ['GarageYrBlt', 'Longitude', 'Latitude', 'Median_n_Closest_SalePrice']\n",
      "\t\t('int', [])       : 35 | ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['CentralAir']\n",
      "\t0.5s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.51 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.52s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4288.93s of the 6434.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.43%)\n",
      "\t-0.1221\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.84s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4282.97s of the 6429.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.48%)\n",
      "\t-0.1255\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.66s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 4265.53s of the 6411.59s of remaining time.\n",
      "\t-0.1399\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.42s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4262.38s of the 6408.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.84%)\n",
      "\t-0.1204\t = Validation score   (-root_mean_squared_error)\n",
      "\t254.83s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 4005.42s of the 6151.49s of remaining time.\n",
      "\t-0.1371\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4003.96s of the 6150.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t-0.132\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.89s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3990.78s of the 6136.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.94%)\n",
      "\t-0.1345\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.18s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3981.91s of the 6127.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t-0.1259\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.42s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3958.22s of the 6104.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.66%)\n",
      "\t-0.1334\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.27s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 428.89s of the 6092.91s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.25, 'NeuralNetTorch_BAG_L1': 0.25, 'LightGBMXT_BAG_L1': 0.2, 'LightGBM_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.1}\n",
      "\t-0.1158\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 6092.78s of the 6092.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
      "\t-0.1225\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.45s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 6080.95s of the 6080.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
      "\t-0.1225\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.71s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 6075.21s of the 6075.20s of remaining time.\n",
      "\t-0.1195\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 6072.38s of the 6072.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.90%)\n",
      "\t-0.1186\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.56s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 6036.65s of the 6036.64s of remaining time.\n",
      "\t-0.1181\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 6035.31s of the 6035.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t-0.1244\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.12s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 6023.15s of the 6023.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.01%)\n",
      "\t-0.1236\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.06s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 6014.74s of the 6014.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t-0.123\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.5s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 5994.64s of the 5994.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.95%)\n",
      "\t-0.1299\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.43s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 609.28s of the 5955.67s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.2, 'CatBoost_BAG_L1': 0.16, 'RandomForestMSE_BAG_L2': 0.16, 'NeuralNetFastAI_BAG_L2': 0.16, 'NeuralNetTorch_BAG_L1': 0.12, 'ExtraTreesMSE_BAG_L2': 0.08, 'CatBoost_BAG_L2': 0.04, 'XGBoost_BAG_L2': 0.04, 'NeuralNetTorch_BAG_L2': 0.04}\n",
      "\t-0.1153\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 480.12s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 64.2 rows/s (183 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t2.57s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t1.9s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.42s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t28.35s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 17.\n",
      "\t14.49s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.47s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t9.93s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t1.19s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.25, 'NeuralNetTorch_BAG_L1': 0.25, 'LightGBMXT_BAG_L1': 0.2, 'LightGBM_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.1}\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t1.12s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.23s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t3.31s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 16.\n",
      "\t12.23s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\t4.17s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t2.49s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.2, 'CatBoost_BAG_L1': 0.16, 'RandomForestMSE_BAG_L2': 0.16, 'NeuralNetFastAI_BAG_L2': 0.16, 'NeuralNetTorch_BAG_L1': 0.12, 'ExtraTreesMSE_BAG_L2': 0.08, 'CatBoost_BAG_L2': 0.04, 'XGBoost_BAG_L2': 0.04, 'NeuralNetTorch_BAG_L2': 0.04}\n",
      "\t0.01s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 85.74s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/alexhubbe/MEGA/data_science/portfolio/house_prices/models\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run the fit method: 1331.76 seconds\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: log-transform the target variable\n",
    "df_train['SalePrice'] = np.log1p(df_train['SalePrice'])  # Log transform target\n",
    "\n",
    "# Identify the target variable\n",
    "label = 'SalePrice'\n",
    "\n",
    "eval_metric = 'rmse'\n",
    "\n",
    "presets = 'good_quality'\n",
    "#'medium_quality'\n",
    "#'good_quality'\n",
    "#'best_quality'\n",
    "\n",
    "time_limit = 60 * 60 * 2\n",
    "\n",
    "\n",
    "# Initialize the TabularPredictor \n",
    "start_time = time.time()\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label, \n",
    "    eval_metric=eval_metric,\n",
    "    path=MODELS_FOLDER\n",
    "    #problem_type='regression'\n",
    ").fit(\n",
    "    train_data=df_train, \n",
    "    time_limit=time_limit, \n",
    "    presets=presets,\n",
    "    #num_cpus=1 \n",
    ")\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the time taken\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to run the fit method: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d08f74d-6ff5-42ae-a711-ce31589734dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-0.115298</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>3.212488</td>\n",
       "      <td>384.397873</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.013353</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.115810</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.717484</td>\n",
       "      <td>305.657179</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-0.118121</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.178495</td>\n",
       "      <td>315.973169</td>\n",
       "      <td>0.103841</td>\n",
       "      <td>0.906463</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-0.118625</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.251878</td>\n",
       "      <td>348.626597</td>\n",
       "      <td>0.177223</td>\n",
       "      <td>33.559891</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-0.119544</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.175480</td>\n",
       "      <td>317.239848</td>\n",
       "      <td>0.100825</td>\n",
       "      <td>2.173142</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_val              eval_metric  pred_time_val  \\\n",
       "0     WeightedEnsemble_L3  -0.115298  root_mean_squared_error       3.212488   \n",
       "1     WeightedEnsemble_L2  -0.115810  root_mean_squared_error       1.717484   \n",
       "2    ExtraTreesMSE_BAG_L2  -0.118121  root_mean_squared_error       2.178495   \n",
       "3         CatBoost_BAG_L2  -0.118625  root_mean_squared_error       2.251878   \n",
       "4  RandomForestMSE_BAG_L2  -0.119544  root_mean_squared_error       2.175480   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  384.397873                0.000299           0.013353            3   \n",
       "1  305.657179                0.000488           0.016258            2   \n",
       "2  315.973169                0.103841           0.906463            2   \n",
       "3  348.626597                0.177223          33.559891            2   \n",
       "4  317.239848                0.100825           2.173142            2   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0      False         20  \n",
       "1      False         10  \n",
       "2      False         15  \n",
       "3      False         14  \n",
       "4      False         13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a9be2d-95d0-4764-90db-a51935693e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = predictor.predict(df_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "predictions = np.expm1(predictions)\n",
    "\n",
    "# Ensure predictions are non-negative (important after inverse transform)\n",
    "predictions = np.maximum(0, predictions)\n",
    "\n",
    "predictions\n",
    "# Create a submission file (Kaggle format)\n",
    "submission = pd.DataFrame({'Id': id, 'SalePrice': predictions})\n",
    "submission.to_csv(KAGGLE_SUBMISSION, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08428ac-2e24-4593-b995-0c62f3adf7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 77 features using 1460 rows with 10 shuffle sets... Time limit: 1800s...\n",
      "\t1472.66s\t= Expected runtime (147.27s per shuffle set)\n",
      "\t813.92s\t= Actual runtime (Completed 10 of 10 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor.feature_importance(df_train, time_limit = 1800, feature_stage='transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19020124-de4c-4a2f-9393-ca18a2f2e457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 77 features using 1460 rows with 10 shuffle sets... Time limit: 1800.0s...\n",
      "\t593.1s\t= Expected runtime (59.31s per shuffle set)\n",
      "\t358.93s\t= Actual runtime (Completed 10 of 10 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor.feature_importance(df_train, time_limit = time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b2cff5-b238-464c-b505-1694c379fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            importance    stddev       p_value   n  p99_high  \\\n",
      "GrLivArea                     0.075621  0.001745  1.487136e-16  10  0.077414   \n",
      "OverallQual                   0.063569  0.001911  1.611185e-15  10  0.065534   \n",
      "TotalBsmtSF                   0.024921  0.001288  2.093243e-13  10  0.026245   \n",
      "OverallCond                   0.024188  0.001336  3.811178e-13  10  0.025562   \n",
      "1stFlrSF                      0.021432  0.001060  1.407991e-13  10  0.022521   \n",
      "YearBuilt                     0.017512  0.000617  6.746361e-15  10  0.018146   \n",
      "Neighborhood                  0.016563  0.000578  6.173498e-15  10  0.017157   \n",
      "BsmtFinSF1                    0.015348  0.001085  3.472932e-12  10  0.016463   \n",
      "LotArea                       0.014749  0.000950  1.508447e-12  10  0.015725   \n",
      "GarageCars                    0.011120  0.000452  2.402704e-14  10  0.011584   \n",
      "2ndFlrSF                      0.010885  0.000630  5.762877e-13  10  0.011532   \n",
      "SaleCondition                 0.008641  0.000483  4.278736e-13  10  0.009137   \n",
      "Median_n_Closest_SalePrice    0.008543  0.000520  9.034500e-13  10  0.009077   \n",
      "YearRemodAdd                  0.008399  0.000475  4.751347e-13  10  0.008888   \n",
      "Latitude                      0.006807  0.000315  7.853698e-14  10  0.007131   \n",
      "GarageArea                    0.006597  0.000356  3.111913e-13  10  0.006963   \n",
      "Fireplaces                    0.006054  0.000214  6.783205e-15  10  0.006273   \n",
      "Longitude                     0.005590  0.000427  6.979460e-12  10  0.006029   \n",
      "CentralAir                    0.005348  0.000309  5.635482e-13  10  0.005665   \n",
      "MSZoning                      0.005032  0.000331  1.846129e-12  10  0.005373   \n",
      "FullBath                      0.004997  0.000258  2.067733e-13  10  0.005262   \n",
      "HalfBath                      0.004850  0.000474  6.361733e-11  10  0.005338   \n",
      "KitchenQual                   0.004848  0.000347  3.867446e-12  10  0.005204   \n",
      "OpenPorchSF                   0.004485  0.000446  7.374811e-11  10  0.004943   \n",
      "GarageYrBlt                   0.004308  0.000175  2.439257e-14  10  0.004488   \n",
      "Condition1                    0.004235  0.000221  2.311715e-13  10  0.004462   \n",
      "BsmtFullBath                  0.004028  0.000497  5.048516e-10  10  0.004539   \n",
      "WoodDeckSF                    0.004010  0.000277  2.790760e-12  10  0.004295   \n",
      "BsmtUnfSF                     0.003673  0.000342  4.149202e-11  10  0.004025   \n",
      "BsmtExposure                  0.003618  0.000439  4.379410e-10  10  0.004069   \n",
      "MoSold                        0.003457  0.000140  2.335992e-14  10  0.003601   \n",
      "ScreenPorch                   0.003452  0.000535  3.815882e-09  10  0.004002   \n",
      "Exterior1st                   0.003302  0.000208  1.231460e-12  10  0.003516   \n",
      "BsmtFinType1                  0.003170  0.000226  3.825566e-12  10  0.003403   \n",
      "HeatingQC                     0.003096  0.000285  3.717471e-11  10  0.003390   \n",
      "MasVnrArea                    0.003083  0.000252  1.294298e-11  10  0.003343   \n",
      "Functional                    0.003013  0.000291  5.694590e-11  10  0.003313   \n",
      "TotRmsAbvGrd                  0.002773  0.000327  3.345679e-10  10  0.003108   \n",
      "LotFrontage                   0.002693  0.000159  6.775807e-13  10  0.002856   \n",
      "YrSold                        0.002615  0.000200  6.984152e-12  10  0.002820   \n",
      "MSSubClass                    0.002538  0.000187  5.069536e-12  10  0.002731   \n",
      "BsmtQual                      0.002498  0.000210  1.664938e-11  10  0.002715   \n",
      "FireplaceQu                   0.002232  0.000128  5.309427e-13  10  0.002364   \n",
      "EnclosedPorch                 0.002178  0.000201  3.757223e-11  10  0.002384   \n",
      "ExterQual                     0.002135  0.000246  2.695000e-10  10  0.002388   \n",
      "GarageFinish                  0.002012  0.000238  3.532736e-10  10  0.002257   \n",
      "Foundation                    0.001988  0.000147  5.149599e-12  10  0.002139   \n",
      "Exterior2nd                   0.001977  0.000141  3.715696e-12  10  0.002122   \n",
      "HouseStyle                    0.001937  0.000374  2.592712e-08  10  0.002321   \n",
      "SaleType                      0.001929  0.000251  8.014723e-10  10  0.002187   \n",
      "LotShape                      0.001806  0.000190  1.220004e-10  10  0.002001   \n",
      "BedroomAbvGr                  0.001723  0.000210  4.542476e-10  10  0.001939   \n",
      "MasVnrType                    0.001399  0.000153  1.721403e-10  10  0.001556   \n",
      "ExterCond                     0.001367  0.000167  4.552562e-10  10  0.001538   \n",
      "LotConfig                     0.001293  0.000168  7.823936e-10  10  0.001465   \n",
      "GarageType                    0.001282  0.000148  2.836215e-10  10  0.001435   \n",
      "BsmtFinSF2                    0.001043  0.000148  1.711478e-09  10  0.001195   \n",
      "KitchenAbvGr                  0.001025  0.000161  4.380550e-09  10  0.001191   \n",
      "BsmtHalfBath                  0.000895  0.000096  1.412326e-10  10  0.000993   \n",
      "PavedDrive                    0.000881  0.000105  3.833270e-10  10  0.000989   \n",
      "PoolArea                      0.000841  0.000398  4.560382e-05  10  0.001250   \n",
      "Fence                         0.000837  0.000121  2.078228e-09  10  0.000961   \n",
      "LandContour                   0.000687  0.000083  4.258615e-10  10  0.000773   \n",
      "BsmtCond                      0.000646  0.000143  8.404470e-08  10  0.000793   \n",
      "GarageQual                    0.000641  0.000107  7.348986e-09  10  0.000751   \n",
      "GarageCond                    0.000601  0.000061  9.372595e-11  10  0.000664   \n",
      "Electrical                    0.000555  0.000118  6.269746e-08  10  0.000677   \n",
      "3SsnPorch                     0.000505  0.000115  1.103131e-07  10  0.000624   \n",
      "RoofStyle                     0.000456  0.000123  4.735738e-07  10  0.000582   \n",
      "LowQualFinSF                  0.000436  0.000064  2.473123e-09  10  0.000502   \n",
      "BldgType                      0.000433  0.000083  2.382398e-08  10  0.000518   \n",
      "Alley                         0.000432  0.000064  2.641543e-09  10  0.000498   \n",
      "MiscVal                       0.000378  0.000043  2.485776e-10  10  0.000422   \n",
      "BsmtFinType2                  0.000376  0.000040  1.466595e-10  10  0.000417   \n",
      "LandSlope                     0.000358  0.000050  1.471230e-09  10  0.000409   \n",
      "Heating                       0.000248  0.000075  1.246416e-06  10  0.000325   \n",
      "MiscFeature                   0.000138  0.000044  1.720277e-06  10  0.000183   \n",
      "\n",
      "                             p99_low  \n",
      "GrLivArea                   0.073828  \n",
      "OverallQual                 0.061605  \n",
      "TotalBsmtSF                 0.023598  \n",
      "OverallCond                 0.022815  \n",
      "1stFlrSF                    0.020343  \n",
      "YearBuilt                   0.016877  \n",
      "Neighborhood                0.015968  \n",
      "BsmtFinSF1                  0.014234  \n",
      "LotArea                     0.013773  \n",
      "GarageCars                  0.010656  \n",
      "2ndFlrSF                    0.010238  \n",
      "SaleCondition               0.008144  \n",
      "Median_n_Closest_SalePrice  0.008009  \n",
      "YearRemodAdd                0.007910  \n",
      "Latitude                    0.006483  \n",
      "GarageArea                  0.006231  \n",
      "Fireplaces                  0.005834  \n",
      "Longitude                   0.005151  \n",
      "CentralAir                  0.005031  \n",
      "MSZoning                    0.004691  \n",
      "FullBath                    0.004732  \n",
      "HalfBath                    0.004363  \n",
      "KitchenQual                 0.004491  \n",
      "OpenPorchSF                 0.004026  \n",
      "GarageYrBlt                 0.004128  \n",
      "Condition1                  0.004008  \n",
      "BsmtFullBath                0.003517  \n",
      "WoodDeckSF                  0.003726  \n",
      "BsmtUnfSF                   0.003321  \n",
      "BsmtExposure                0.003166  \n",
      "MoSold                      0.003314  \n",
      "ScreenPorch                 0.002902  \n",
      "Exterior1st                 0.003089  \n",
      "BsmtFinType1                0.002938  \n",
      "HeatingQC                   0.002803  \n",
      "MasVnrArea                  0.002824  \n",
      "Functional                  0.002714  \n",
      "TotRmsAbvGrd                0.002437  \n",
      "LotFrontage                 0.002530  \n",
      "YrSold                      0.002410  \n",
      "MSSubClass                  0.002346  \n",
      "BsmtQual                    0.002282  \n",
      "FireplaceQu                 0.002101  \n",
      "EnclosedPorch               0.001972  \n",
      "ExterQual                   0.001883  \n",
      "GarageFinish                0.001767  \n",
      "Foundation                  0.001837  \n",
      "Exterior2nd                 0.001832  \n",
      "HouseStyle                  0.001553  \n",
      "SaleType                    0.001671  \n",
      "LotShape                    0.001611  \n",
      "BedroomAbvGr                0.001507  \n",
      "MasVnrType                  0.001242  \n",
      "ExterCond                   0.001195  \n",
      "LotConfig                   0.001120  \n",
      "GarageType                  0.001130  \n",
      "BsmtFinSF2                  0.000892  \n",
      "KitchenAbvGr                0.000859  \n",
      "BsmtHalfBath                0.000797  \n",
      "PavedDrive                  0.000772  \n",
      "PoolArea                    0.000431  \n",
      "Fence                       0.000712  \n",
      "LandContour                 0.000602  \n",
      "BsmtCond                    0.000500  \n",
      "GarageQual                  0.000531  \n",
      "GarageCond                  0.000538  \n",
      "Electrical                  0.000433  \n",
      "3SsnPorch                   0.000387  \n",
      "RoofStyle                   0.000329  \n",
      "LowQualFinSF                0.000370  \n",
      "BldgType                    0.000348  \n",
      "Alley                       0.000366  \n",
      "MiscVal                     0.000334  \n",
      "BsmtFinType2                0.000334  \n",
      "LandSlope                   0.000307  \n",
      "Heating                     0.000171  \n",
      "MiscFeature                 0.000094  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fffeced1-3cbd-49f7-ac9e-20c7ecdfb217",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(predictor\u001b[38;5;241m.\u001b[39mtransform_features(model\u001b[38;5;241m=\u001b[39m{\u001b[43mmodel_name\u001b[49m})\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "list(predictor.transform_features(model={model_name}).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "097a586b-3ec5-4aea-8005-2dd064e281a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "predictor.model_best()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:autogluon]",
   "language": "python",
   "name": "conda-env-autogluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
